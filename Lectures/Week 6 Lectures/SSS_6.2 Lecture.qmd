---
title: "Social Sciences Intro to Statistics"
subtitle: "Week 6.2 Comparing Two Groups (Continued)"
format: pdf
editor: source
---
Week 6: Learning goal - Evaluate two groups with hypothesis testing and comparing population means.

 
```{r, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", highlight = TRUE, warning = FALSE, message = FALSE)
  #comment = "#>" makes it so results from a code chunk start with "#>"; default is "##"
```

# Introduction
Lecture overview:

- Fundamental concepts in causal inference

- Hypothesis testing comparing population means of two groups

Load packages:
```{r, message=FALSE, echo=FALSE}
library(tidyverse)
library(ggplot2)
library(labelled)
library(patchwork)


# Load ipeds dataset from course website
load(url('https://raw.githubusercontent.com/bcl96/Social-Sciences-Stats/main/data/ipeds/output_data/panel_data.RData'))
```


```{r, echo=FALSE}
# Create ipeds data frame with fewer variables/observations
df_ipeds_pop <- panel_data %>%
  # keep data from fall 2022
  filter(year == 2022) %>%
  # which universities to keep:
    # 2015 carnegie classification: keep research universities (15,16,17) and master's universities (18,19,20)
  filter(c15basic %in% c(15,16,17,18,19,20)) %>%
  # which variables to keep
  select(instnm,unitid,opeid6,opeid,control,c15basic,stabbr,city,zip,locale,obereg, # basic institutional characteristics
         tuition6,fee6,tuition7,fee7, # avg tuition and fees for full-time grad, in-state and out-of-state
         isprof3,ispfee3,osprof3,ospfee3, # avg tuition and fees for MD, in-state and out-of-state
         isprof9,ispfee9,osprof9,ospfee9, # avg tuition and fees for Law, in-state and out-of-state
         chg4ay3,chg7ay3,chg8ay3) %>% # [undergraduate] books+supplies; off-campus (not with family) room and board; off-campus (not with family) other expenses
  # rename variables; syntax <new_name> = <old_name>
  rename(region = obereg, # revion
         tuit_grad_res = tuition6, fee_grad_res = fee6, tuit_grad_nres = tuition7, fee_grad_nres = fee7, # grad
         tuit_md_res = isprof3, fee_md_res = ispfee3, tuit_md_nres = osprof3, fee_md_nres = ospfee3, # md
         tuit_law_res = isprof9, fee_law_res = ispfee9, tuit_law_nres = osprof9, fee_law_nres = ospfee9, # law
         books_supplies = chg4ay3, roomboard_off = chg7ay3, oth_expense_off = chg8ay3) %>% # [undergraduate] expenses
  # create measures of tuition+fees
  mutate(
    tuitfee_grad_res = tuit_grad_res + fee_grad_res, # graduate, state resident
    tuitfee_grad_nres = tuit_grad_nres + fee_grad_nres, # graduate, non-resident
    tuitfee_md_res = tuit_md_res + fee_md_res, # MD, state resident
    tuitfee_md_nres = tuit_md_nres + fee_md_nres, # MD, non-resident
    tuitfee_law_res = tuit_law_res + fee_law_res, # Law, state resident
    tuitfee_law_nres = tuit_law_nres + fee_law_nres) %>% # Law, non-resident  
  # create measures of cost-of-attendance (COA) as the sum of tuition, fees, book, living expenses
  mutate(
    coa_grad_res = tuit_grad_res + fee_grad_res + books_supplies + roomboard_off + oth_expense_off, # graduate, state resident
    coa_grad_nres = tuit_grad_nres + fee_grad_nres + books_supplies + roomboard_off + oth_expense_off, # graduate, non-resident
    coa_md_res = tuit_md_res + fee_md_res + books_supplies + roomboard_off + oth_expense_off, # MD, state resident
    coa_md_nres = tuit_md_nres + fee_md_nres + books_supplies + roomboard_off + oth_expense_off, # MD, non-resident
    coa_law_res = tuit_law_res + fee_law_res + books_supplies + roomboard_off + oth_expense_off, # Law, state resident
    coa_law_nres = tuit_law_nres + fee_law_nres + books_supplies + roomboard_off + oth_expense_off) %>% # Law, non-resident    
  # keep only observations that have non-missing values for the variable coa_grad_res
    # this does cause us to lose some interesting universities, but doing this will eliminate some needless complications with respect to learning core concepts about statistical inference
  filter(!is.na(coa_grad_res))

# Add variable labels to the tuit+fees variables and coa variables
  # tuition + fees variables
    var_label(df_ipeds_pop[['tuitfee_grad_res']]) <- 'graduate, full-time, resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_grad_nres']]) <- 'graduate, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_res']]) <- 'MD, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_md_nres']]) <- 'MD, full-time, non-resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_res']]) <- 'Law, full-time, state resident; avg tuition + required fees'
    var_label(df_ipeds_pop[['tuitfee_law_nres']]) <- 'Law, full-time, non-resident; avg tuition + required fees'
    
  # COA variables
    var_label(df_ipeds_pop[['coa_grad_res']]) <- 'graduate, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_grad_nres']]) <- 'graduate, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_res']]) <- 'MD, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_md_nres']]) <- 'MD, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_res']]) <- 'Law, full-time, state resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'
    var_label(df_ipeds_pop[['coa_law_nres']]) <- 'Law, full-time, non-resident COA; == tuition + fees + (ug) books/supplies + (ug) off-campus room and board + (ug) off-campus other expenses'

df_ipeds_pop %>% glimpse()


##########
########## Create data frame of generated variables, with each variable meant to represent the entire population
##########


num_obs <- 10000

# Generate normal distribution w/ custom mean and sd
set.seed(124)
norm_dist <- rnorm(n = num_obs, mean = 50, sd = 5)

# Generate right-skewed distribution
set.seed(124)
rskew_dist <- rbeta(n = num_obs, shape1 = 2, shape2 = 5)

# Generate left-skewed distribution
set.seed(124)
lskew_dist <- rbeta(n = num_obs, shape1 = 5, shape2 = 2)

# Generate standard normal distribution (default is mean = 0 and sd = 1)
set.seed(124)
stdnorm_dist <- rnorm(n = num_obs, mean = 0, sd = 1)  # equivalent to rnorm(10)

# Create dataframe
df_generated_pop <- data.frame(norm_dist, rskew_dist, lskew_dist, stdnorm_dist)

# drop individual objects associated with each variable
rm(norm_dist,rskew_dist,lskew_dist,stdnorm_dist)
rm(num_obs)


##########
########## Create sample versions of generated population data frame and IPEDS population data frame
##########

# create sample version of our generated data
  set.seed(124) # set seed so that everyone ends up with the same random sample
  
  df_generated_sample <- df_generated_pop %>% sample_n(size = 200)
  df_generated_sample %>% glimpse()


# create sample version of our ipeds data

  set.seed(124) # set seed so that everyone ends up with the same random sample
  
  df_ipeds_sample <- df_ipeds_pop %>% sample_n(size = 200) 
  
  # compare mean of coa_grad_res between population and sample
  mean(df_ipeds_pop$coa_grad_res, na.rm = TRUE)
  mean(df_ipeds_sample$coa_grad_res, na.rm = TRUE)

##########
########## STAR DATA
##########

# load star data
load(url("https://raw.githubusercontent.com/bcl96/Social-Sciences-Stats/main/data/star/star_panel_data.RData"))

#df_star_panel %>% glimpse()

# create data frame for STAR experiment, keeping only kindergarten
df_stark <- df_star_panel %>% 
  # keep only kindergarten year
  filter(grade ==1) %>% 
  # keep only observations with non-missing value for reading score
  filter(!is.na(read)) %>%
  # keep only observations with non-missing values for treatment assignment
  filter(!is.na(star)) %>%
  # drop observations where treatment status is regular+aide
  filter(star !=3) %>%
  # keep selected variables
  select(id,grade,star,read,gender,ethnicity,lunch,school,degree,experience) %>%
  # create a variable "treatment" that equals 1 if student receives treatment (small class) and equals 0 otherwise
  mutate(
    treatment = if_else(star==2,1,0)
  )


df_stark %>% glimpse()
```

## Fundamental concepts in causal inference
Causal inference is the process of determining the independent, actual effect of a particular phenomenon that is a component of a larger system. 

- More simply, the process of identifying the effect of an independent variable on an outcome of interest

Here's the difference between descriptive research questions and causal research questions:

Descriptive research questions

- Can investigate the magnitude of a problem (univariate):
	- What percentage of high school graduates attend college?
- Investigate correlational relationship between variables (sometimes called "associational" relationships):
	- Relationship between buying felt furniture pads and credit score?
	- Relationship between avg. income at a high school and the number of off-campus recruiting visits by universities?

Causal research questions

- Want to know the "causal effect" of independent variable (X) on outcome (Y); If you change value of X, causal effect is the change in Y due to the change in X
- Have the form "what is effect of X on Y?" Examples: 
  - What is the effect of class size on math scores? 
  - What is effect of grant aid on graduation?

We will use the following example research questions to explain causal inference concepts:

**What is the effect of having a "small" class size ($T_i=1$) vs. "large" class size ($T_i=0$) on reading test score ($Y$) for elementary school students?**
    - This research question is from the Tennessee Student Teacher Achievement Ratio (STAR) experiment
    - We have data from this experiment
    - [LINK](https://dataverse.harvard.edu/dataset.xhtml?persistentId=hdl:1902.1/10766) to information and data on the Tennessee STAR project
 
## Hypothesis testing comparing population means of two groups

### Investigate STAR data
We want to know if Kindergarten students randomly assigned to the "small" class size (variable `treatment` equals `1`) have higher values of reading test score than students randomly assigned to the "large" class size (variable `treatment` equals `0`)

So let's state $H_0$ null hypothesis and $H_a$ alternative hypothesis:

null hypothesis ($H_0$)

- $H_0: \mu_{Y_{{treated}}} = \mu_{Y_{{control}}}$
- (in words): $H_0:$ the population mean reading score for kindergarten students assigned to the treatment (small class size), $\mu_{Y_{{treated}}}$, is the same as the population mean reading score for kindergarten students assigned to the control (big class size) ($\mu_{Y_{{control}}}$)

Two-sided alternative hypothesis ($H_a$)

- $H_0: \mu_{Y_{{treated}}} \ne \mu_{Y_{{control}}}$
- (in words): $H_0:$ the population mean reading score for kindergarten students assigned to the treatment (small class size), $\mu_{Y_{{treated}}}$, is different than the population mean reading score for kindergarten students assigned to the control (big class size) ($\mu_{Y_{{control}}}$)

Remember the general formula for (any) test statistic

$$ test\_statistic = \frac{sample\_estimate - value\_associated\_with\_H_0}{sample\_standard\_error}$$

**Formula for test statistic about two population means**

$t = \frac{(\bar{Y}_2 - \bar{Y}_1)- 0}{\hat{\sigma}_{\bar{Y}_2 - \bar{Y}_1}} = \frac{sample\_estimate - value\_associated\_with\_H_0}{sample\_standard\_error}$

- $\bar{Y}_2$ is sample mean of group 2
- $\bar{Y}_1$ is sample mean of group 1
- $\hat{\sigma}_{\bar{Y}_2 - \bar{Y}_1}$ is the sample standard error of $\bar{Y}_2 - \bar{Y}_1$
- *Note*: doesn't matter which group is group 1 and which is group 2


- $\hat{\sigma}_{\bar{Y}_2 - \bar{Y}_1}= \sqrt{\frac{\hat{\sigma}_{Y_1}^2}{n_1}+\frac{\hat{\sigma}_{Y_2}^2}{n_2}}$
  - $n_1$ is the sample size of group 1
  - $n_2$ is the sample size of group 2
  - $\hat{\sigma}_{Y_1}^2$ is the sample standard deviation of group 1, squared
  - $\hat{\sigma}_{Y_2}^2$ is the sample standard deviation of group 2, squared
  
**Calculating t-statistic for Tennessee STAR example, by hand**
Let's start first by calculating by hand to get more practice understanding the different steps to finding the t-statistic

```{r}
df_stark %>% group_by(treatment) %>% 
  summarize(
    n = n(),
    n_nonmiss = sum(!is.na(read)),
    mean = mean(read, na.rm = TRUE),
    sd = sd(read, na.rm = TRUE)
  )

# point estimate - H_0_value
  (440.5474 - 434.7323) - 0
  
# standard error
  sqrt(30.93590^2/2006 + 32.49738^2/1739)
  
# t-statistic = (point estimate - H_0_value)/(standard error)
  (440.5474 - 434.7323)/sqrt(30.93590^2/2006 + 32.49738^2/1739)
```

Interpreting values

- point estimate = `5.815`
  - the sample mean reading score for treated (small class) students is 5.815 larger than the sample mean reading score for untreated (large class) students
- standard error = `1.041`
  - on average the point estimate $\bar{Y}_{treated}-\bar{Y}_{control}$ a single random sample is 1.04 away from the mean of point estimates from an infinite number of random samples
- t-statistic = `5.584`
  - under the assumption that $H_0$ is true (i.e., $\mu_{Y_{{treated}}} - \mu_{Y_{{control}}}=0$) the observed point estimate is 5.584 standard errors away from the value associated with $H_0$ (i.e., `0`)

**Calculating t-statistic for Tennessee STAR example using `t.test()` function**


`t.test()` function, using the "formula" method

- syntax:
  - `t.test(formula, data, subset, mu=0, alternative = c("two.sided", "less", "greater"))`
- selected arguments
  - `formula`: follows form `formula = y_var ~ x_var`
    - where `y_var` is the outcome variable and `x_var` is the variable that defines the two groups you are comparing
  - `data`: data frame that contains variables named in `formula`
  - `alternative`: whether you want two-sided or one-sided alternative hypothesis (default is `two.sided`)
  - `subset`: subset of data to test (useful if `x_var` has more than two groups and you want to restrict test to those two groups)
  - `mu`: value associated with null hypothesis (default is `0`)
  
```{r}
#?t.test
t.test(formula = read ~ treatment, mu = 0, data = df_stark)
```

## p-value and Conclusion

Definition of p-value (same as for hypothesis test about a single population mean)

- Under the assumption if null hypothesis is true, the **p-value** is the probability of observing a point estimate as far away from the null hypothesis value as the one we observed

Above, we observed a p-value of less than `0.01`, indicating it would be very unlikely to observe the point estimate we observed ($\bar{Y}_{treated}-\bar{Y}_{control}=$ `r round(mean(df_stark$read[df_stark$treatment==1], na.rm = TRUE) - mean(df_stark$read[df_stark$treatment==0], na.rm = TRUE), digits = 2)`) under the assumption that $H_0$ is true

Let's use an alpha level of `.05` to determine whether to reject $H_0$

Conclusion:

- The p-value of 0.00 is less than the alpha level of `.05`. Therefore, we reject $H_0$ and accept $H_a$
- In words, the population mean reading score for kindergarten students assigned to the treatment (small class size), $\mu_{Y_{{treated}}}$, is different than the population mean reading score for kindergarten students assigned to the control (big class size) ($\mu_{Y_{{control}}}$)
- Furthermore, we can say that the population mean reading score for students in the treatment is larger than the population mean reading score for students in the control group.




